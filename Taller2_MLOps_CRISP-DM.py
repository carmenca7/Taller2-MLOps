# -*- coding: utf-8 -*-
"""Taller2_MLOps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HEilImXCtGU3tNlceqWNYp3c28-ZgkSv

#Taller 2 - MLOps
##Carmen Carvajal Gutiérrez

#Entendimiento del Negocio

##Objetivo del Negocio:
El objetivo principal es predecir la probabilidad de quiebra de una empresa con base en indicadores financieros.
*   Gestión del riesgo crediticio: Ayudar a bancos e instituciones financieras a tomar decisiones informadas sobre la aprobación de créditos o préstamos.

##Objetivo Analítico:
Construir un modelo de Machine Learning para clasificar las empresas en dos categorías, No quebrada y Quebrada, acorde a sus indicadores financieros. El modelo debe ser capaz de predecir la probabilidad de quiebra con un rendimiento robusto.
"""

# Importar las bibliotecas necesarias para el análisis y modelado
import pandas as pd  # Para manipulación y análisis de datos
import numpy as np   # Para operaciones numéricas
import matplotlib.pyplot as plt  # Para visualizaciones y gráficos
import seaborn as sns  # Para visualización estadística

# Importar herramientas de scikit-learn para preparación y evaluación de modelos
from sklearn.model_selection import train_test_split  # Para dividir los datos en train y test
from sklearn.model_selection import GridSearchCV, cross_val_score  # Para validación cruzada
from sklearn.preprocessing import StandardScaler  # Para normalizar las variables
from sklearn.metrics import (
    classification_report,  # Reporte detallado de métricas
    confusion_matrix,      # Matriz de confusión
    roc_auc_score,        # Área bajo la curva ROC
    roc_curve,            # Para graficar curva ROC
    f1_score,             # Métrica F1
    precision_score,      # Precisión
    recall_score          # Recall/Sensibilidad
)

# Importar los modelos de clasificación que se van a evaluar
from sklearn.linear_model import LogisticRegression  # Regresión logística básica
from sklearn.ensemble import RandomForestClassifier  # Bosques aleatorios
from sklearn.ensemble import GradientBoostingClassifier  # Gradient Boosting
from sklearn.svm import SVC  # Support Vector Machine
from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors
from sklearn.neural_network import MLPClassifier  # Red neuronal multicapa
from sklearn.tree import DecisionTreeClassifier  # Árbol de decisión
from sklearn.ensemble import VotingClassifier, StackingClassifier  # Métodos de ensamblaje para combinar modelos

# Importar herramientas para manejar el desbalance de clases
from imblearn.over_sampling import SMOTE  # Técnica de sobremuestreo sintético para balancear clases

# Desactivar warnings para una salida más limpia
import warnings
warnings.filterwarnings('ignore')

"""#Entendimiento de los datos"""

# Cargar los datos
file_path = '/content/data.csv'
data = pd.read_csv(file_path)

#Primeras 5 filas del dataset para entender su estructura
data.head()

# Información básica sobre el tamaño del dataset
print("(filas, columnas):")
print(data.shape)

#Validación de valores nulos en el dataset
print("\nInformación detallada del conjunto de datos:")
data.info()

# Estadísticas descriptivas básicas del dataset
data.describe()

# Análisis de la distribución de la variable objetivo
target_distribution = data['Bankrupt?'].value_counts()

# Porcentaje de cada clase
target_percentage = target_distribution / target_distribution.sum() * 100

# Resumen de la distribución
target_summary = pd.DataFrame({
    'Count': target_distribution,
    'Percentage': target_percentage
})

# Visualización de la distribución de la variable objetivo
plt.figure(figsize=(8, 6))
plt.bar(target_summary.index.astype(str), target_summary['Count'], alpha=0.7)
plt.title('Distribución de la variable objetivo: Bankrupt?', fontsize=14)
plt.xlabel('Clases (0 = No Quiebra, 1 = Quiebra)', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

print("\nResumen de la distribución de la variable objetivo:")
print(target_summary)

"""#Preparación de los datos"""

# DETECCIÓN Y MANEJO DE OUTLIERS (VALORES ATÍPICOS)

# Identificar las columnas numéricas (features)
numerical_cols = data.columns.drop('Bankrupt?')

# Visualizar la distribución y outliers de cada variable con boxplots
plt.figure(figsize=(20, 15))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(10, 10, i)
    sns.boxplot(y=data[col])
    plt.title(col, fontsize=8)
plt.tight_layout()
plt.show()

# Tratamiento de outliers mediante winsorización (reemplazar valores extremos por el percentil 1 y 99)
for col in numerical_cols:
    lower_percentile = data[col].quantile(0.01)
    upper_percentile = data[col].quantile(0.99)
    data[col] = np.where(data[col] < lower_percentile, lower_percentile, data[col])
    data[col] = np.where(data[col] > upper_percentile, upper_percentile, data[col])

# BALANCEO DE CLASES CON SMOTE

# Separar caracteristicas (X) y variable objetivo (y)
X = data.drop('Bankrupt?', axis=1)  # Variables predictoras
y = data['Bankrupt?']  # Variable objetivo

# Mostrar la distribución inicial de clases
print("\nDistribución de clases antes del balanceo:")
print(y.value_counts())

# Aplicar SMOTE para balancear las clases
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X, y)

print("Distribución de clases después de aplicar SMOTE:")
print(pd.Series(y_balanced).value_counts())

# NORMALIZACIÓN DE VARIABLES

# Aplicar StandardScaler para normalizar las variables
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_balanced)

# DIVISIÓN EN TRAIN Y TEST

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y_balanced,
    test_size=0.2,  # 20% para test
    random_state=42,  # Para reproducibilidad de resultados
    stratify=y_balanced  # Mantener proporción de clases
)

print(f"Muestras de entrenamiento: {X_train.shape[0]}")
print(f"Muestras de prueba: {X_test.shape[0]}")

# FUNCIÓN DE EVALUACIÓN

def evaluate_model(model, X_test, y_test):
    # Realizar predicciones
    y_pred = model.predict(X_test)
    # Obtener probabilidades predichas (o decision function para SVM)
    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, "predict_proba") else model.decision_function(X_test)

    # Calcular múltiples métricas
    return {
        'ROC AUC': roc_auc_score(y_test, y_proba),
        'F1 Score': f1_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred)
    }

"""#Modelación"""

# PARÁMETROS PARA GridSearchSV
# Definir los rangos de parámetros a probar para cada modelo
param_grids = {
    'lr': {  # Parámetros para Regresión Logística
        'C': [0.001, 0.01, 0.1, 1.0, 10.0],
        'penalty': ['l2'],
        'solver': ['lbfgs', 'liblinear']
    },
    'rf': {  # Parámetros para Random Forest
        'n_estimators': [100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    },
    'gb': {  # Parámetros para Gradient Boosting
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1],
        'max_depth': [3, 5],
        'min_samples_split': [2, 5]
    }
}

# GridSearchSV PARA MODELOS BASE
# Función para la optimización de hiperparámetros para cada modelo base
def get_tuned_models():
    tuned_models = {}

    # Optimización de Regresión Logística
    print("\nOptimizando Regresión Logística...")
    lr = LogisticRegression(random_state=42, max_iter=1000)
    lr_grid = GridSearchCV(lr, param_grids['lr'], cv=5, scoring='roc_auc', n_jobs=-1)
    lr_grid.fit(X_train, y_train)
    tuned_models['lr'] = lr_grid.best_estimator_
    print("Mejores parámetros:", lr_grid.best_params_)

    # Optimización de Random Forest
    print("\nOptimizando Random Forest...")
    rf = RandomForestClassifier(random_state=42)
    rf_grid = GridSearchCV(rf, param_grids['rf'], cv=5, scoring='roc_auc', n_jobs=-1)
    rf_grid.fit(X_train, y_train)
    tuned_models['rf'] = rf_grid.best_estimator_
    print("Mejores parámetros:", rf_grid.best_params_)

    # Optimización de Gradient Boosting
    print("\nOptimizando Gradient Boosting...")
    gb = GradientBoostingClassifier(random_state=42)
    gb_grid = GridSearchCV(gb, param_grids['gb'], cv=5, scoring='roc_auc', n_jobs=-1)
    gb_grid.fit(X_train, y_train)
    tuned_models['gb'] = gb_grid.best_estimator_
    print("Mejores parámetros:", gb_grid.best_params_)

    return tuned_models

# Obtener modelos optimizados
tuned_models = get_tuned_models()

# DEFINICIÓN Y ENTRENAMIENTO DE MODELOS

# Definir modelos para comparar su rendimiento
models = {
    'Logistic Regression': tuned_models['lr'],
    'Random Forest': tuned_models['rf'],
    'Gradient Boosting': tuned_models['gb'],
    'Support Vector Machine': SVC(probability=True, random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Neural Network': MLPClassifier(random_state=42, max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

# Entrenar y evaluar cada modelo
results = {}
for name, model in models.items():
    print(f"\nEntrenando {name}...")
    if name not in ['Logistic Regression', 'Random Forest', 'Gradient Boosting']:  # Saltar modelos ya entrenados
        model.fit(X_train, y_train)
    metrics = evaluate_model(model, X_test, y_test)
    results[name] = metrics
    print(f"Métricas para {name}:")
    print(metrics)

# IMPLEMENTACIÓN DEL CLASIFICADOR POR VOTACIÓN
# Combinar las predicciones de múltiples modelos mediante votación
def train_voting_classifier(tuned_models):
    print("\nEntrenando Clasificador por Votación...")
    voting_clf = VotingClassifier(
        estimators=[
            ('lr', tuned_models['lr']),
            ('rf', tuned_models['rf']),
            ('gb', tuned_models['gb'])
        ],
        voting='soft'  # Usa probabilidades en lugar de predicciones directas
    )

    voting_clf.fit(X_train, y_train)
    voting_metrics = evaluate_model(voting_clf, X_test, y_test)
    print("Métricas del Clasificador por Votación:")
    print(voting_metrics)

    return voting_clf

# IMPLEMENTACIÓN DEL CLASIFICADOR POR APILAMIENTO
# Utilizar las predicciones de los modelos base como entrada para un meta-clasificador
def train_stacking_classifier(tuned_models):
    print("\nEntrenando Clasificador por Apilamiento...")
    meta_classifier = LogisticRegression(random_state=42)

    stacking_clf = StackingClassifier(
        estimators=[
            ('lr', tuned_models['lr']),
            ('rf', tuned_models['rf']),
            ('gb', tuned_models['gb'])
        ],
        final_estimator=meta_classifier,  # Clasificador final que combina las predicciones
        cv=5,                            # Validación cruzada para entrenamiento
        stack_method='predict_proba'      # Usa probabilidades para el apilamiento
    )

    stacking_clf.fit(X_train, y_train)
    stacking_metrics = evaluate_model(stacking_clf, X_test, y_test)
    print("Métricas del Clasificador por Apilamiento:")
    print(stacking_metrics)

    return stacking_clf

# Entrenar métodos de ensamblaje
voting_clf = train_voting_classifier(tuned_models)
stacking_clf = train_stacking_classifier(tuned_models)

"""#Evaluación"""

# COMPARACIÓN DE MODELOS

# Función para comparar todos los modelos incluyendo los ensamblajes
def compare_all_models(base_results, voting_clf, stacking_clf):
    # Añadir resultados de modelos base
    all_results = base_results.copy()

    # Añadir resultados del Clasificador por Votación
    voting_metrics = evaluate_model(voting_clf, X_test, y_test)
    all_results['Clasificador por Votación'] = voting_metrics

    # Añadir resultados del Clasificador por Apilamiento
    stacking_metrics = evaluate_model(stacking_clf, X_test, y_test)
    all_results['Clasificador por Apilamiento'] = stacking_metrics

    # Crear DataFrame de comparación
    comparison_df = pd.DataFrame(all_results).T
    comparison_df = comparison_df[['ROC AUC', 'F1 Score', 'Precision', 'Recall']]

    # Ordenar por puntuación F1 Score
    comparison_df = comparison_df.sort_values(by='F1 Score', ascending=False)

    # Visualizar resultados
    plt.figure(figsize=(12, 6))
    sns.barplot(x=comparison_df.index, y='F1 Score', data=comparison_df)
    plt.title('Comparación de Todos los Modelos incluyendo Ensamblajes')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    return comparison_df

# Comparar todos los modelos
print("\nComparación Final de Modelos:")
final_comparison = compare_all_models(results, voting_clf, stacking_clf)
print("\nMétricas detalladas para todos los modelos:")
print(final_comparison)

"""## Métrica de desempeño más importante
La métrica de desempeño más importante en este caso es el F1-Score; ya que se esta trabajando con un conjunto de datos altamente desequilibrado, en el que el número de empresas No bancarrotas supera significativamente al de empresas en bancarrota.
- Maximizar el Recall: Asegurando que la mayoría de las empresas en quiebra sean identificadas correctamente.
- Maximizar la Precisión: Minimizando el número de empresas que no están en quiebra y que son señaladas incorrectamente como en quiebra.

#Mejor modelo

Todos los modelos evaluados muestran un buen desempeño, con métricas que superan el 90% en términos de ROC AUC, F1 Score, Precisión y Recall. Sin embargo, dado el desequilibrio que presenta el conjunto de datos, donde las empresas en bancarrota representan la clase minoritaria, y considerando que la métrica de mayor relevancia para este caso es el F1-Score, el modelo Red Neural se destaca como el más adecuado. Este modelo logra un F1-Score 98.76%, y un balance casi perfecto entre precisión y recall asegurando la identificación de los casos positivos reales (empresas en bancarrota), lo cual es importante en este contexto específico.

#¿Valdría la pena usar el mejor modelo en el día a día de una empresa/institución?
Sí, valdría la pena, pero se debe tener en cuenta ciertas consideraciones:
- Infraestructura y Recursos: Si la empresa tiene la capacidad de implementar y mantener un modelo basado en redes neuronales, este modelo puede generar un valor significativo.
- Implementación y Supervisión: Sería necesario monitorear constantemente el modelo en producción para asegurarse de que mantenga su desempeño en el tiempo, ajustándolo cuando cambien las condiciones del mercado.
- Costo-Beneficio: Para justificar la complejidad del modelo, el beneficio financiero debe superar el costo de implementación y mantenimiento.
- Alternativas: Si la empresa no dispone de los recursos necesarios, modelos como el Gradient Boosting o incluso el Random Forest, que también tienen un alto desempeño y suelen ser menos exigentes en términos de recursos, podrían ser opciones viables.
"""